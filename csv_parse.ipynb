{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing Conversations from a scraped forum \n",
        "This notebook is optimized for (non-paid) google collab\n",
        "The steps are:\n",
        "- Data Import (from google drive currently)\n",
        "- Inital Parse, select relevent data and save\n",
        "- Read Data back from CSV and parse thoroughly\n",
        "  - save results"
      ],
      "metadata": {
        "id": "ufcJFkmE3omo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "snX6jMJ8MLrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21927edb-f0aa-495c-8e90-8f4a26adc026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "#from nltk.stem import SnowballStemmer\n",
        "!pip install gdown\n",
        "!pip install --upgrade gdown\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "nT7NiUyVMQ5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This replaces the need to import Forum157.7z into the machine"
      ],
      "metadata": {
        "id": "MDcNW-SQa8sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/164ZTc7EB4my1mRBVv-K-tREx4EMDmKY8/view?usp=share_link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRjtjYczch9Y",
        "outputId": "fc220aba-a2e6-4461-ea81-01ccb5020810"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=164ZTc7EB4my1mRBVv-K-tREx4EMDmKY8\n",
            "From (redirected): https://drive.google.com/uc?id=164ZTc7EB4my1mRBVv-K-tREx4EMDmKY8&confirm=t&uuid=c6fab1b3-1530-4b57-bbb3-71a137c42fe6\n",
            "To: /content/Forum157.7z\n",
            "100% 1.14G/1.14G [00:18<00:00, 61.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/parsedData\n",
        "!mkdir /content/data\n",
        "\n",
        "#Untar into data folder\n",
        "!7za x -o/content/data -y Forum157.7z"
      ],
      "metadata": {
        "id": "D_9ToMTTa03y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdebbdd8-a10d-4b1d-ffb2-859bcb04ac73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1144004002 bytes (1092 MiB)\n",
            "\n",
            "Extracting archive: Forum157.7z\n",
            "--\n",
            "Path = Forum157.7z\n",
            "Type = 7z\n",
            "Physical Size = 1144004002\n",
            "Headers Size = 398\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 5\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - BlackHatWorld.txt_Part0.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - BlackHatWorld.txt_Part1.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 2 - BlackHatWorld.txt_Part10.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 3\b\b\b\b\b\b      \b\b\b\b\b\b 19% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 3 - BlackHatWorld.txt_Part2.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 4 - BlackHatWorld.txt_Part3.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 5\b\b\b\b\b\b      \b\b\b\b\b\b 39% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 5 - BlackHatWorld.txt_Part4.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 6 - BlackHatWorld.txt_Part5.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 7\b\b\b\b\b\b      \b\b\b\b\b\b 59% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 7 - BlackHatWorld.txt_Part6.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 8 - BlackHatWorld.txt_Part7.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 9\b\b\b\b\b\b      \b\b\b\b\b\b 80% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 9 - BlackHatWorld.txt_Part8.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 10 - BlackHatWorld.txt_Part9.txt\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 11\b\b\b\b\b\b\b       \b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 11\n",
            "Size:       15947249423\n",
            "Compressed: 1144004002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inital Parse, select relevent data (text body)"
      ],
      "metadata": {
        "id": "xikuXkF1gZ_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converts each (of the 11) file from .txt to .csv\n",
        "for i in range(11):\n",
        "  path = \"/content/data/BlackHatWorld.txt_Part\"+str(i)+\".txt\"\n",
        "  read_file = pd.read_csv (path,sep='\\t')\n",
        "  # This file is seperated by \\t spaces\n",
        "\n",
        "  #Select only the text\n",
        "  read_file = read_file.filter(items=[\"txtBody_Clean\"])\n",
        "\n",
        "  #Save into a new 'parsed' csv in parsedData directory\n",
        "  savePath = \"/content/parsedData/parsedText_part\"+str(i)+\".csv\"\n",
        "  read_file.to_csv (savePath, index=None)\n",
        "  print(\"File \" + str(i) +\" is done\")"
      ],
      "metadata": {
        "id": "NWzUUIGWZIzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658689d0-7921-400c-c27b-38baeb87cb77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 0 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 1 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 2 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 3 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 4 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 5 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 6 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 7 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 8 is done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6c4b2afa08ca>:4: DtypeWarning: Columns (5,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  read_file = pd.read_csv (path,sep='\\t')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 9 is done\n",
            "File 10 is done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del read_file # Frees up some memory ( i hope )"
      ],
      "metadata": {
        "id": "hzrXSTUReuFf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatonate all the csv's together\n",
        "!cat /content/parsedData/parsedText_part*.csv > outputfile.csv"
      ],
      "metadata": {
        "id": "MN0GBtSBYO7N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read Data back from CSV and parse thoroughly\n",
        "\n",
        "Read the data back into a dataframe, then use pandas dataframe to do our parsing techniques"
      ],
      "metadata": {
        "id": "LKSmzAuklYlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/outputfile.csv', header=None, names=['text'])"
      ],
      "metadata": {
        "id": "vjONz5Wslc9Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "WeIk3Mxem9CO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1867b9c0-9674-4908-e758-981cec388b1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                       text\n",
            "0                                             txtBody_Clean\n",
            "1         Cloaking is a search engine optimization techn...\n",
            "2         Do the search engines allow this. If they disc...\n",
            "3         Often when you get a high ranking page under q...\n",
            "4         There are 5 types of cloaking:        * User A...\n",
            "...                                                     ...\n",
            "10015344  I saw this about a year ago. Without looking t...\n",
            "10015345  Yes Pxoxrxn, i totally agree that we're advanc...\n",
            "10015346  pxoxrxn said:                      â†‘          ...\n",
            "10015347  Just for anyone that is interested, this guy h...\n",
            "10015348  It looks mostly geared towards people that hav...\n",
            "\n",
            "[10015349 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows containing NaN values\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "UAcxqafJW8vk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "id": "x4Q0sANlahhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a50d75-3176-44cd-c146-efb83c400d43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9976012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars = df.applymap(lambda x: len(str(x))).sum().sum()\n",
        "print(total_chars)"
      ],
      "metadata": {
        "id": "bJ_e91LnjJHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227bb400-3dd3-4830-dfa4-b9c01ceeda24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3598866267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows that contain the string header \"txtBody_Clean\"\n",
        "df = df[~df['text'].str.contains('txtBody_Clean')]"
      ],
      "metadata": {
        "id": "IgIRRwpwWQjb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows containing NaN values (double check)\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "T_xEIaVCWf2b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "id": "aPS38EZSajF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e80601b-53df-4681-9a0f-880cab15cb28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9976001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxPUeAJqjGe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will not truncate long text, to better visualize the parse\n",
        "# Access a row of the DataFrame\n",
        "row = df.iloc[44744]\n",
        "\n",
        "# Set the maximum column width to display (unlimited)\n",
        "pd.options.display.max_colwidth = None\n",
        "\n",
        "print(row)"
      ],
      "metadata": {
        "id": "wD0B8vWCWmqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f99805-8cf3-4149-821b-c731eb7d3c65"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text    joking as many Nigerians associated with scams.. but not the only meme but really looks like really high percent doing bad things, don't take to hard was just unsalted joke, sorry if I offended someone\n",
            "Name: 44787, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].str.split(\"var dark_postrating\", n=1, expand=True)[0]\n",
        "#Cut out rest of the string afer footer text"
      ],
      "metadata": {
        "id": "niEfHSYeUhzh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df['text'] = df['text'].str.split(\"last edited by a moderator\", n=1, expand=True)[0]\n",
        "#Cut out rest of the string afer modifications"
      ],
      "metadata": {
        "id": "mIv5q3r_xzai"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern matching replies from previous posts\n",
        "pattern = 'said:.*?Click to expand\\.'\n",
        "\n",
        "# Use str.replace to remove the matching pattern\n",
        "df['text'] = df['text'].str.replace(pattern, '', regex=True)\n",
        "\n",
        "# Erase thanks\n",
        "df['text'] = df['text'].str.replace(r'Thanks x \\d+', '')"
      ],
      "metadata": {
        "id": "KqFb-dODWwlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17864fb1-25df-4501-e202-e0dcbdd7cfd0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-09823fe6f43c>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text'] = df['text'].str.replace(r'Thanks x \\d+', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replace links with simpler version i.e. -> https://www.pinecone.io/learn/bertopic/ -> wwwpineconeiolearnbertopic\n",
        "# Replace the URLs with simplified form\n",
        "df['text'] = df['text'].str.replace('https://www.', 'www')\n",
        "df['text'] = df['text'].str.replace('/', '')"
      ],
      "metadata": {
        "id": "iRaMI8EBncQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743a0ed0-55b5-4367-c3d0-f40ebe64cec9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-0fe20e35d3d3>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text'] = df['text'].str.replace('https://www.', 'www')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKANox0cDulV",
        "outputId": "41dd36df-d302-4717-ab92-a6b5a299ba24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text\n",
            "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Cloaking is a search engine optimization technique in which the content presented to the search engine spider is different from that presented to the users' browser; this is done by delivering content based on the IP addresses or the User-Agent HTTP header of whatever is requesting the page. The only legitimate uses for cloaking used to be for delivering content to users that search engines couldn't parse, like Macromedia Flash. However, cloaking is often used to try to trick search engines into giving the relevant site a higher ranking; it can also be used to trick search engine users into visiting a site based on the search engine description which site turns out to have substantially different - or even pornographic - content.\n",
            "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Do the search engines allow this. If they discover what you are doing will they reduce your page ranking?\n",
            "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Often when you get a high ranking page under quality keywords the first thing that will happen is your page gets stolen (called PageJacking). Often that page is stolen just to put up a duplicate some where and reduce your rankings. Yes, that is what happens with many engines. They see the duplicate and think duplicate and mysteriously your page disappears in the next search engine update.    So, it's easy to imagine what happens on what's regarding cloaking. Search engine cloaking is just one aspect of a much bigger picture. This is why search engines can't even consider banning cloaking. It is so widespread and pervasive, they'd have to delete 14th of the domains in their indexes - those would be the best sites they have listed.\n",
            "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     There are 5 types of cloaking:        * User Agent Cloaking (UA Cloaking)      * IP Agent Cloaking (IP Cloaking)      * IP and User Agent Cloaking (IPUA Cloaking).      * Referral based cloaking.      * Session based cloaking.\n",
            "5         1)  User Agent cloaking is good for taking care of specific agents. Wap, Wml pages for the cell phone crowd.        Active X for the IE crowd.        Quality css from the Moz and Opera crowd.        Nice black screen for the web tv'ers.        Specialty content for agents (eg: NoSmartTags, GoogleBot Noarchive)        No sense in sending out stuff with js, java, or flash than a user can't actually run.      2) IP Address Cloaking is good for taking care of demographic groups. Language file generation for various countries.        Advertising delivery based on geo data.        Pages built for broad band users.        Low impact pages for overseas users.        User-time-of-day determination and custom content based on tod geo data (news, sports weather..etc)        Specifically targeting demo groups such as AOL, Mindspring etal.      3) IP and Agent cloaking is good for a combo of the above. Custom content for AOL'ers using Wap phones.        Ads based upon geo data and user agent support.        The possibilities for targeting are almost endless. You'll run out of ways to reroll it before you run out of ips and agents to serve.        Indexability. Just getting your site fully indexed can be a challenge in some environments (flash, shock).      4) Referrer based cloaking is basing delivery on specific referral strings. It is good for content generation such as overriding frames (about.com, ask jeeves, and the google image cache).        Preventing unwanted Hotlinking to your graphics.      5) Session based cloaking. Sites that use session tracking (either from ip, or cookies), can do incredible things with content. We've all seen session cloaking in action on dynamic sites were custom content was generated for us.\n",
            "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...\n",
            "10015344                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I saw this about a year ago. Without looking too far into it, I'm going to just say that it would be extremely limited. I can't imagine the websites being anything more than HTML, CSS and JavaScript.            Â                                                                                                      Thanks  x 3                                                \n",
            "10015345                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Yes Pxoxrxn, i totally agree that we're advancing technologically, but i can't imagine an artificial intelligence machine building a website completely.. It would certainly be a ready for use website with just javascript, CSS and HTML, not to forget, all the websites would be the exact replica of each other..    Talk about making google work easier for them to catch spam            Â                                                                                                      Thanks  x 1                                                \n",
            "10015346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     pxoxrxn ..      Seems I'm rather late to the party, then!    And I agree entirely - it's not exactly AI... it's just a pre-programmed algo, like any other.\n",
            "10015347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Just for anyone that is interested, this guy has written 8.5% of all Wikipedia content by creating his own bot which has written 2.7 million wikipedia articles thus far;    http:www.smh.com.autechnologyte...ng-published-on-wikipedia-20140716-ztbao.html    Nothing is impossible, but to create an entire website would take a lot of coding.            Â                                                                                                      Thanks  x 2                                                \n",
            "10015348                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         It looks mostly geared towards people that have personal blogs and not commercial ones.\n",
            "\n",
            "[9976001 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bertopic will handle the rest of the parsing -> This helps the model understand the nature of the text better"
      ],
      "metadata": {
        "id": "j6pfbtnu-H7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## erase non-alphanumeric characters\n",
        "#df['text'] = df['text'].str.replace('[^\\w\\s]', '')"
      ],
      "metadata": {
        "id": "BcxqvLSslrDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use str.lower to convert each string to lowercase --- \n",
        "#df['text'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "lHGV-1aHosCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the data"
      ],
      "metadata": {
        "id": "ZTAiz0BuFenc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv (r'/content/output_simple.csv', index=None)"
      ],
      "metadata": {
        "id": "acuJmqPLeQym"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output_simple.csv.zip output_simple.csv"
      ],
      "metadata": {
        "id": "sMT9sLOpir3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cd5087-4fbc-4362-847b-b08846b8d691"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output_simple.csv (deflated 68%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars2 = df.applymap(lambda x: len(str(x))).sum().sum()\n",
        "print(total_chars2)"
      ],
      "metadata": {
        "id": "OPk10NH2kEYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d85b475-06d3-4a2f-ab05-a9b962c9d5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2572135870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncommenting the following lines and running it will cause an infinite loop.\n",
        "# Only do so for a couple of seconds to see a snapshot of the conversations\n",
        "#import itertools\n",
        "##for post in itertools.cycle(df['text']):\n",
        "#    print(post)"
      ],
      "metadata": {
        "id": "YDsfOOMy1JmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional Additional Parsing"
      ],
      "metadata": {
        "id": "owEW6LORACmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming is a technique used in natural language processing to reduce complexity\n",
        "#it is the process of removing the suffixes from words to reduce them to their stem.\n",
        "\n",
        "# Initialize Snowball Stemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# Stem every row in the DataFrame\n",
        "df['text'] = df['text'].apply(lambda x: stemmer.stem(x))"
      ],
      "metadata": {
        "id": "clvokwl8XTIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv (r'/content/output_complex.csv', index=None)"
      ],
      "metadata": {
        "id": "T0GXU1kdeXnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -dd output_complex.csv.zip output_complex.csv"
      ],
      "metadata": {
        "id": "noT3O7WTjT-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac96fdc-ea54-4aab-a091-3ecff1623641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output_complex.csv ...................................................................................................................................................................................................................................................... (deflated 71%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_chars3 = df.applymap(lambda x: len(str(x))).sum().sum()\n",
        "print(total_chars3)"
      ],
      "metadata": {
        "id": "EFv9ZAOxjLgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5e476b-6675-4e48-9a8a-9bfd4ee8c239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2565275318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In summary:"
      ],
      "metadata": {
        "id": "3YHFQ7_EANBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total character to begin with: \" + str(total_chars))\n",
        "print(\"Total character after parsing: \" + str(total_chars2))\n",
        "print(\"Total character after parsing + stemming: \" + str(total_chars3))\n",
        "\n",
        "print(\"\\nParsing makes the data \" + str(1 - (total_chars2/total_chars)) + \" lighter\")\n",
        "print(\"Stemming makes the data \"+str(1 - (total_chars3/total_chars))+ \" lighter\")\n",
        "print(\"0.28 == 28% !\")"
      ],
      "metadata": {
        "id": "vLzPj_XnAPny",
        "outputId": "e35385ab-04c6-4dc2-a088-9282abda546d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total character to begin with: 3598866267\n",
            "Total character after parsing: 2572135870\n",
            "Total character after parsing + stemming: 2565275318\n",
            "\n",
            "Parsing makes the data 0.2852927341075884 lighter\n",
            "Stemming makes the data 0.28719904334250157 lighter\n",
            "0.28 = 28% !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the non-stemmed data (output_simple.csv) to keep coherency as it does not make a drastic differnece"
      ],
      "metadata": {
        "id": "DtPxyp7bFMwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we will get the identical data, and usernames associated with the posts:\n",
        "\n",
        "This has to be run after loading in the data\n"
      ],
      "metadata": {
        "id": "a8PWuFbL852R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Converts each (of the 11) file from .txt to .csv\n",
        "!mkdir parsed_with_author\n",
        "for i in range(11):\n",
        "  path = \"/content/data/BlackHatWorld.txt_Part\"+str(i)+\".txt\"\n",
        "  read_file = pd.read_csv (path,sep='\\t')\n",
        "  # This file is seperated by \\t spaces\n",
        "\n",
        "  #Select only the text\n",
        "  read_file = read_file.filter(items=[\"txtBody_Clean\",\"txtAuthor\"])\n",
        "\n",
        "  #Save into a new 'parsed' csv in parsed_with_author directory\n",
        "  savePath = \"/content/parsed_with_author/parsedText_part\"+str(i)+\".csv\"\n",
        "  read_file.to_csv (savePath, index=None)\n",
        "  print(\"File \" + str(i) +\" is done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "UyJYDk879Di9",
        "outputId": "97bf30c0-6b9b-4b72-8b1d-e7b9ada64dd4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜parsed_with_authorâ€™: File exists\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-31b49b899e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/data/BlackHatWorld.txt_Part\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mread_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;31m# This file is seperated by \\t spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m     \"\"\"\n\u001b[1;32m   1431\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del read_file # Frees up some memory ( i hope )"
      ],
      "metadata": {
        "id": "VLvAAIeK_RWK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatonate all the csv's together\n",
        "!cat /content/parsed_with_author/parsedText_part*.csv > outputfile_with_authors.csv"
      ],
      "metadata": {
        "id": "qyoaeIaj_RWL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read Data back from CSV and parse identically to output_simple\n",
        "\n",
        "- We are doing it this way as models and notebooks already use output_simple so we have to make a different file to keep the original intact\n",
        "\n",
        "Read the data back into a dataframe, then use pandas dataframe to do our parsing techniques"
      ],
      "metadata": {
        "id": "v4Yq-lUX_RWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/outputfile_with_authors.csv', header=None, names=['text','author'])"
      ],
      "metadata": {
        "id": "c_5-U_aL_RWL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f437c20f-3e11-49e1-9e08-9f88436875c1",
        "id": "s8yeZLPH_RWL"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                       text          author\n",
            "0                                             txtBody_Clean       txtAuthor\n",
            "1         Cloaking is a search engine optimization techn...  Diamond Damien\n",
            "2         Do the search engines allow this. If they disc...         Timothy\n",
            "3         Often when you get a high ranking page under q...          twirly\n",
            "4         There are 5 types of cloaking:        * User A...          twirly\n",
            "...                                                     ...             ...\n",
            "10015344  I saw this about a year ago. Without looking t...         pxoxrxn\n",
            "10015345  Yes Pxoxrxn, i totally agree that we're advanc...       wisdomkid\n",
            "10015346  pxoxrxn said:                      â†‘          ...          tony_d\n",
            "10015347  Just for anyone that is interested, this guy h...         mrankin\n",
            "10015348  It looks mostly geared towards people that hav...   Capo Dei Capi\n",
            "\n",
            "[10015349 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows containing NaN values\n",
        "df = df[df['text'].notna()]"
      ],
      "metadata": {
        "id": "3FYxePTA_RWM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4db5d9-54ef-436e-c635-1ea4e440ccce",
        "id": "s9-HSE0S_RWM"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9976012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the rows that contain the string header \"txtBody_Clean\"\n",
        "df = df[~df['text'].str.contains('txtBody_Clean')]"
      ],
      "metadata": {
        "id": "BuJ5mVUS_RWM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill author names with any value \"0\"\n",
        "df[\"author\"] = df[\"author\"].fillna(0)"
      ],
      "metadata": {
        "id": "YxZlXd8m_RWN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994c8b66-f1ee-4ba8-d17e-1842acdb74c1",
        "id": "Dtxin166_RWN"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9976001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hoWw_ZQu_RWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This will not truncate long text, to better visualize the parse\n",
        "# Access a row of the DataFrame\n",
        "row = df.iloc[44744]\n",
        "\n",
        "# Set the maximum column width to display (unlimited)\n",
        "pd.options.display.max_colwidth = None\n",
        "\n",
        "print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1545e244-7fda-4bb0-9001-f1c109ded765",
        "id": "QK755I9__RWO"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text      joking as many Nigerians associated with scams.. but not the only meme but really looks like really high percent doing bad things, don't take to hard was just unsalted joke, sorry if I offended someone\n",
            "author                                                                                                                                                                                                 faxingberlin\n",
            "Name: 44787, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].str.split(\"var dark_postrating\", n=1, expand=True)[0]\n",
        "#Cut out rest of the string afer footer text"
      ],
      "metadata": {
        "id": "9G4UQpAf_RWO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df['text'] = df['text'].str.split(\"last edited by a moderator\", n=1, expand=True)[0]\n",
        "#Cut out rest of the string afer modifications"
      ],
      "metadata": {
        "id": "ZJPl6FWi_RWP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern matching replies from previous posts\n",
        "pattern = 'said:.*?Click to expand\\.'\n",
        "\n",
        "# Use str.replace to remove the matching pattern\n",
        "df['text'] = df['text'].str.replace(pattern, '', regex=True)\n",
        "\n",
        "# Replace thanks \n",
        "df['text'] = df['text'].str.replace(r'Thanks x \\d+', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFPSn_wC_RWP",
        "outputId": "b6cd5fb1-c67a-4ca0-d9e7-26fc9e8da022"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-baf031edc9a6>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['text'] = df['text'].str.replace(r'Thanks x \\d+', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replace links with simpler version i.e. -> https://www.pinecone.io/learn/bertopic/ -> wwwpineconeiolearnbertopic\n",
        "df['text'] = df['text'].str.replace('https://www.', 'www', regex=True)\n",
        "df['text'] = df['text'].str.replace('/', '')"
      ],
      "metadata": {
        "id": "5lNYd_9B_RWP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQoDtehiNox1",
        "outputId": "9c823419-a87f-4d04-d564-1bc291031d16"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text  \\\n",
            "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Cloaking is a search engine optimization technique in which the content presented to the search engine spider is different from that presented to the users' browser; this is done by delivering content based on the IP addresses or the User-Agent HTTP header of whatever is requesting the page. The only legitimate uses for cloaking used to be for delivering content to users that search engines couldn't parse, like Macromedia Flash. However, cloaking is often used to try to trick search engines into giving the relevant site a higher ranking; it can also be used to trick search engine users into visiting a site based on the search engine description which site turns out to have substantially different - or even pornographic - content.   \n",
            "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Do the search engines allow this. If they discover what you are doing will they reduce your page ranking?   \n",
            "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Often when you get a high ranking page under quality keywords the first thing that will happen is your page gets stolen (called PageJacking). Often that page is stolen just to put up a duplicate some where and reduce your rankings. Yes, that is what happens with many engines. They see the duplicate and think duplicate and mysteriously your page disappears in the next search engine update.    So, it's easy to imagine what happens on what's regarding cloaking. Search engine cloaking is just one aspect of a much bigger picture. This is why search engines can't even consider banning cloaking. It is so widespread and pervasive, they'd have to delete 14th of the domains in their indexes - those would be the best sites they have listed.   \n",
            "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     There are 5 types of cloaking:        * User Agent Cloaking (UA Cloaking)      * IP Agent Cloaking (IP Cloaking)      * IP and User Agent Cloaking (IPUA Cloaking).      * Referral based cloaking.      * Session based cloaking.   \n",
            "5         1)  User Agent cloaking is good for taking care of specific agents. Wap, Wml pages for the cell phone crowd.        Active X for the IE crowd.        Quality css from the Moz and Opera crowd.        Nice black screen for the web tv'ers.        Specialty content for agents (eg: NoSmartTags, GoogleBot Noarchive)        No sense in sending out stuff with js, java, or flash than a user can't actually run.      2) IP Address Cloaking is good for taking care of demographic groups. Language file generation for various countries.        Advertising delivery based on geo data.        Pages built for broad band users.        Low impact pages for overseas users.        User-time-of-day determination and custom content based on tod geo data (news, sports weather..etc)        Specifically targeting demo groups such as AOL, Mindspring etal.      3) IP and Agent cloaking is good for a combo of the above. Custom content for AOL'ers using Wap phones.        Ads based upon geo data and user agent support.        The possibilities for targeting are almost endless. You'll run out of ways to reroll it before you run out of ips and agents to serve.        Indexability. Just getting your site fully indexed can be a challenge in some environments (flash, shock).      4) Referrer based cloaking is basing delivery on specific referral strings. It is good for content generation such as overriding frames (about.com, ask jeeves, and the google image cache).        Preventing unwanted Hotlinking to your graphics.      5) Session based cloaking. Sites that use session tracking (either from ip, or cookies), can do incredible things with content. We've all seen session cloaking in action on dynamic sites were custom content was generated for us.   \n",
            "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
            "10015344                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I saw this about a year ago. Without looking too far into it, I'm going to just say that it would be extremely limited. I can't imagine the websites being anything more than HTML, CSS and JavaScript.            Â                                                                                                      Thanks  x 3                                                   \n",
            "10015345                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Yes Pxoxrxn, i totally agree that we're advancing technologically, but i can't imagine an artificial intelligence machine building a website completely.. It would certainly be a ready for use website with just javascript, CSS and HTML, not to forget, all the websites would be the exact replica of each other..    Talk about making google work easier for them to catch spam            Â                                                                                                      Thanks  x 1                                                   \n",
            "10015346                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     pxoxrxn ..      Seems I'm rather late to the party, then!    And I agree entirely - it's not exactly AI... it's just a pre-programmed algo, like any other.   \n",
            "10015347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Just for anyone that is interested, this guy has written 8.5% of all Wikipedia content by creating his own bot which has written 2.7 million wikipedia articles thus far;    http:www.smh.com.autechnologyte...ng-published-on-wikipedia-20140716-ztbao.html    Nothing is impossible, but to create an entire website would take a lot of coding.            Â                                                                                                      Thanks  x 2                                                   \n",
            "10015348                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         It looks mostly geared towards people that have personal blogs and not commercial ones.   \n",
            "\n",
            "                  author  \n",
            "1         Diamond Damien  \n",
            "2                Timothy  \n",
            "3                 twirly  \n",
            "4                 twirly  \n",
            "5                 twirly  \n",
            "...                  ...  \n",
            "10015344         pxoxrxn  \n",
            "10015345       wisdomkid  \n",
            "10015346          tony_d  \n",
            "10015347         mrankin  \n",
            "10015348   Capo Dei Capi  \n",
            "\n",
            "[9976001 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv (r'/content/output_simple_with_authors.csv', index=None)"
      ],
      "metadata": {
        "id": "ff9oPkVMNwEe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip output_simple_with_authors.csv.zip output_simple_with_authors.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d584e5-8314-477f-d9de-4bb4b41e6e44",
        "id": "Np_h6UKdNwEf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output_simple_with_authors.csv (deflated 68%)\n"
          ]
        }
      ]
    }
  ]
}